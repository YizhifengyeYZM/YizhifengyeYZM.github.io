---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from:
- /about/
- /about.html
---

<p><span class="anchor" id="about-me"></span></p>

<p>
  My name is <a class="red-label">Zemin Yang</a> and I am a master student in <a href="https://www.shanghaitech.edu.cn/">ShanghaiTech University</a> focusing on 3D Computer Vision and Embodied AI at <a href="https://4dvlab.github.io/">4DV Lab</a>. My passion lies in refining and revolutionizing the interaction behavior in Embodied AI. I'm particularly interested in in the interaction between humans and Embodied AI Agents.
</p>
<p>
  My goal üìå is to help human interacts with robots, devices and data utilizing AI in a more efficient and natural way.
</p>

<p>
  
</p>
<p>
  
</p>
<p>
  
</p>

<!-- <div class="announcement">
  üì£ &nbsp; I am seeking a Ph.D. position in HCI, starting from Fall
  1.    If you are interested in my research or would like to
  collaborate, please feel free to reach out. Download my <a href="./assets/CV.pdf">CV</a> here.
</div> -->

<!-- <div class="research-wrapper">
  <div class="venn-wrapper">
    <div class="my-venn">
      <div class="overlap">
        <div class="overlap-group">
          <img class="ellipse" src="images/svg/ellipse-1.svg" />
          <img class="img" src="images/svg/ellipse-2.svg" />
          <img class="ellipse-2" src="images/svg/ellipse-3.svg" />
          <img class="AI" src="images/svg/ai.svg" />
          <img class="device" src="images/svg/device.svg" />
          <img class="human" src="images/svg/human.svg" />
          <img class="arrow" src="images/svg/arrow-1.svg" />
          <img class="arrow-2" src="images/svg/arrow-2.svg" />
          <img class="arrow-3" src="images/svg/arrow-3.svg" />
          <img class="line" src="images/svg/line-1.svg" />
          <img class="line-2" src="images/svg/line-3.svg" />
        </div>
        <img class="line-3" src="images/svg/line-3.svg" />
        <img class="interaction-proxy" src="images/svg/interaction-proxy-manager-imwut-22.svg" />
        <img class="OOVVCI" src="images/svg/oovvci-imwut-23.svg" />
        <img class="simulatar" src="images/svg/simulatar-chi-23.svg" />
      </div>
    </div>
  </div>

  <div class="text-wrapper">
    <div class="text-wrapper-see">
      <p>
        My research focuses on the interplay between End Users,
        Computational Platforms, and AI.
      <ul>
        <li>
          Human-Device Interaction: I
          study UI/UX design to enhance efficiency and satisfaction,
          leveraging insights from users' cognitive models. </li>
        <li>Device-AI
          Interaction: I explore devices that shift towards intelligent
          decision-making, addressing algorithm optimization and
          adaptive learning. </li>
        <li>Human-AI Interaction: I delve into how
          humans understand and interact with AI, emphasizing
          transparency, explainability, and reliability.</li>
      </ul> Additionally,
      I'm keen on emerging areas like Multimodal Interaction and
      Context-aware Computing, targeting intuitive and smart
      interactions.
      </p>
    </div>
    <div class="text-wrapper-unsee">
      <p>
        My research focuses on the interplay between End Users,
        Computational Platforms, and AI.
      <ul>
        <li>
          Human-Device Interaction </li>
        <li>Device-AI
          Interaction</li>
        <li>Human-AI Interaction</li>
      </ul>
      </p>
    </div>
  </div>
</div> -->

<h1 id="-publications">üìù Publications</h1>
<p style="color: #3f446a; margin: 0%; font-weight: 350;">* indicates equal contributions</p>



<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge-coming"><b>Coming Soon</b></div>
      <img src="images/HUMOR.png" alt="sym" width="100%" />
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <a style="text-decoration: underline;">HUMOR: Towards Building A World Model of Human Motion in Dynamic Social Scenes</a>
    </p>
    <p>
      Anonymous Authors <b>(As 4th author)</b>
    </p>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge-coming"><b>Coming Soon</b></div>
      <img src="images/EvolvingGrasp.png" alt="sym" width="100%" />
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <a style="text-decoration: underline;" href="https://evolvinggrasp.github.io/">EvolvingGrasp: Evolutionary Grasp Generation via Efficient Preference Alignment</a>
    </p>
    <p>
      Yufei Zhu*, Yiming Zhong*, <b>Zemin Yang</b>, Peishan Cong, Jingyi Yu, Xinge Zhu, Yuexin Ma
    </p>
    <p>This paper introduces EvolvingGrasp, which integrates Handpose-wise Preference Optimization with a Physics-aware Consistency Model to enable efficient evolutionary grasp generation, achieving improved grasp success rates and computational efficiency. </p>
    <a href="./assets/pubs/EvolvingGrasp.pdf" class="pdf-link" target="_blank">PDF</a>
    <a href="https://arxiv.org/abs/2503.14329" class="paper-box-link" target="_blank">Paper</a>
    <a href="https://evolvinggrasp.github.io/" class="paper-box-link" target="_blank">Github <i class="fab fa-github"></i> </a>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge-IMWUT"><b>CVPR 2025</b></div>
      <img src="images/EasyHOI.png" alt="sym" width="100%" />
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <a style="text-decoration: underline;" href="https://lym29.github.io/EasyHOI-page/">EasyHOI: Unleashing the Power of Large Models for Reconstructing Hand-Object Interactions in the Wild</a>
    </p>
    <p>
      Yumeng Liu, Xiaoxiao Long, <b>Zemin Yang</b>, Yuan Liu, Marc Habermann, Christian Theobalt, Yuexin Ma, Wenping Wang
    </p>
    <p>This paper explores reconstructing hand-object interactions from a single-view image. We develop a pipeline to estimate hand pose and object shape using large models and apply a prior-guided optimization to adjust the hand pose, ensuring it meets 3D physical constraints while aligning with the 2D image. </p>
    <a href="./assets/pubs/EasyHOI.pdf" class="pdf-link" target="_blank">PDF</a>
    <a href="https://arxiv.org/abs/2411.14280" class="paper-box-link" target="_blank">Paper</a>
    <a href="https://github.com/lym29/EasyHOI" class="paper-box-link" target="_blank">Github <i
        class="fab fa-github"></i> </a>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge-IMWUT"><b>AAAI 2025</b></div>
      <img src="images/UniDemoire.png" alt="sym" width="100%" />
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <a href="https://yizhifengyeyzm.github.io/UniDemoire-page/" style="text-decoration: underline;">UniDemoir√©: Towards Universal Image Demoir√©ing with Data Generation and Synthesis</a>
    </p>
    <p>
      <b>Zemin Yang*</b>, Yujing Sun*, Xidong Peng, Siu Ming Yiu, Yuexin Ma
    </p>
    <p>This paper proposes a universal image demoir√©ing solution, UniDemoir√©, which has superior generalization capability. Notably, we propose innovative and effective data generation and synthesis methods that can automatically provide vast high-quality moir√© images to train a universal demoir√©ing model. </p>
    <a href="./assets/pubs/UniDemoire.pdf" class="pdf-link" target="_blank">PDF</a>
    <a href="https://yizhifengyeyzm.github.io/UniDemoire-page/" class="paper-box-link" target="_blank">Project Page</a>
    <a href="https://github.com/4DVLab/UniDemoire" class="paper-box-link" target="_blank">Github <i class="fab fa-github"></i> </a>
  </div>
</div>


<!-- <div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge-coming">Coming Soon</div>
      <img src="images/AutoTask.png" alt="sym" width="100%" />
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <a style="text-decoration: underline;" href="/AutoTask">AutoTask: Executing Arbitrary Voice Commands by Exploring
        and Learning from Mobile GUI</a>
    </p>
    <p>
      <b>Bowen Wang*</b>, Lihang Pan*, Chun Yu, Yuxuan Chen,
      Xiangyu Zhang, Yuanchun Shi
    </p>
    <p>This paper presents AutoTask, a VCI capable of automating any task in any mobile application without
      configuration or modification from developers or end users. AutoTask executes VCIs on mobile (i.e. Android
      smartphones) by exploring and learning from UIs.</p>
    <a href="./assets/pubs/AutoTask.pdf" class="pdf-link" target="_blank">PDF</a>
    <a href="https://arxiv.org/abs/2312.16062" class="paper-box-link" target="_blank">Paper</a>
    <a href="https://github.com/BowenBryanWang/AutoTask" class="paper-box-link" target="_blank">Github <i
        class="fab fa-github"></i> </a>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge-coming">Coming Soon</div>
      <img src="images/SimulataR.png" alt="sym" width="100%" />
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <a style="text-decoration: underline;">SimulataR: Exploring the Feasibility of Using Design-Blended Videos for
        Rapid Prototyping of Assisted
        Reality</a>
    </p>
    <p>
      Anonymous Authors <b>(As 2nd author)</b>
    </p>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge-IMWUT">IMWUT 2022</div>
      <img src="images/IPM.png" alt="sym" width="100%" />
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <a href="https://dl.acm.org/doi/10.1145/3610929" style="text-decoration: underline;">Interaction Proxy
        Manager: Semantic Model Generation and
        Run-time Support for Reconstructing Ubiquitous User
        Interfaces of Mobile Services</a>
    </p>
    <p>
      Tian Huang, Chun Yu, Weinan Shi, <b>Bowen Wang</b>,
      David Yang, Yihao Zhu, Zhaoheng Li, Yuanchun Shi
    </p>
    <p>This paper introduces the Interaction Proxy, enabling mobile apps to adapt to new devices without a
      complete rebuild. Key contributions include the UIAD model and the IPManager tool, streamlining
      integration across platforms like mobile-smartwatch and mobile-vehicle.</p>
    <a href="./assets/pubs/imwut22e-sub6665-cam-i26.pdf" class="pdf-link" target="_blank">PDF</a>
    <a href="https://dl.acm.org/doi/10.1145/3610929" class="paper-box-link" target="_blank">Paper</a>
  </div>
</div> -->


<h1 id="-honors-and-awards">üéñ Honors and Awards</h1>

<ul>
  <li>
    <a class="red-label">06/2024</a> Outstanding Graduate Award <b>(Top 10%)</b>
  </li>

  <li>
    <a class="red-label">06/2023</a> 1st Award in the 13th Mathercup Mathematical Contest in Modeling
  </li>

  <li>
    <a class="red-label">02/2023</a> Meritorious Winner in the American Collegiate Mathematical Contest in Modeling
  </li>

  <li>
    <a class="red-label">11/2022</a> Ranking 99 in the CCF Big Data and Computational Intelligence Competition <b>(Top 4%)</b>
  </li>

  <li>
    <a class="red-label">10/2022</a> 1st Award in the China Undergraduate Mathematical Contest in Modeling at Hubei Region
  </li>

  <!-- <li>
    <a class="red-label">09/2023</a> Research and Innovation Scholarship <b>(Top
      1%)</b>
  </li>

  <li>
    <a class="red-label">05/2023</a> 2rd Award of Challenge Cup at Tsinghua University <b>(Top
      10%)</b>
  </li> -->


</ul>

<h1 id="-educations">üìñ Educations</h1>

<ul>

  <li style="display: block;">
    <div class="edu-box">
      <img style="width: 15pt; height: 15pt; margin: 5pt;" src="images/svg/a.svg" />
      <div>
        <p style="color: black; margin: 0%; font-weight: 350;">
          <a class="red-label">2024 - Now </a> Master of Computer Science and Technology</p>
        <p style="color: rgba(0,0,0,.6); font-size: 10pt; margin: 0%;"> ShanghaiTech University</p>
      </div>
    </div>
  </li>

  <li style="display: block;">
    <div class="edu-box">
      <img style="width: 15pt; height: 15pt; margin: 5pt;" src="images/svg/a.svg" />
      <div>
        <p style="color: black; margin: 0%; font-weight: 350;">
          <a class="red-label">2019 - 2024</a> Bachelor of Data Science and Big Data Technology </p>
        <p style="color: rgba(0,0,0,.6); font-size: 10pt; margin: 0%;"> China University of Geoscience (Wuhan)</p>
      </div>
    </div>
  </li>

</ul>

<!-- <h1 id="-invited-talks">üí¨ Invited Talks</h1>

          <ul>
            <li>
              <em>2021.06</em>, Lorem ipsum dolor sit amet, consectetur
              adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo
              dapibus sit amet.
            </li>
            <li>
              <em>2021.03</em>, Lorem ipsum dolor sit amet, consectetur
              adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo
              dapibus sit amet. | <a href="https://github.com/">[video]</a>
            </li>
          </ul> -->

<!-- <h1 id="-internships">üíª Internships</h1>

<ul>
  <li>
    <a class="red-label">06/2023 - Now</a>
    <b>Research Intern</b> at NUS-HCI group, National University of Singapore
  </li>
  <li>
    <a class="red-label">05/2023 - Now</a>
    <b>Co-funder</b> of <a href="https://ai-anywhere.com/">AI-anywhere</a>
  </li>

  <li>
    <a class="red-label">2021.09 - Now</a>
    <b>Undergraduate Research Assistant</b> at PCG group, Tsinghua University
  </li>
</ul> -->

<h1 id="-hobbies">üé® Hobbies</h1>
<p style="color: black; margin: 0%; font-weight: 350;">
  üì∑ <a class="red-label" href="https://500px.com.cn/yizhifengye">Photography</a>, ‚öΩ Football, üèÄ Basketball, üéÆ FPS Games
</p>
<!-- <ul>
  <li>
    <p style="color: black; margin: 0%; font-weight: 350;">üì∑ Photography</p>
  </li>
  <li>
    <p style="color: black; margin: 0%; font-weight: 350;">‚öΩ Football</p>
  </li>
  <li>
    <p style="color: black; margin: 0%; font-weight: 350;">üèÄ Basketball</p>
  </li>
  <li>
    <p style="color: black; margin: 0%; font-weight: 350;">üéÆ FPS Games</p>
  </li>

</ul> -->